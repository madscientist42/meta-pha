From 74214b5efcb9314cce29dbe726e8d67c5832ccbd Mon Sep 17 00:00:00 2001
From: Jianming Qiao <jianming.qiao@bp.renesas.com>
Date: Fri, 13 Sep 2019 00:52:28 +0100
Subject: [PATCH] Remove GPU and NNAPI

Signed-off-by: Jianming Qiao <jianming.qiao@bp.renesas.com>
---
 .../lite/examples/label_image/label_image.cc       | 52 ----------------------
 1 file changed, 52 deletions(-)

diff --git a/tensorflow/lite/examples/label_image/label_image.cc b/tensorflow/lite/examples/label_image/label_image.cc
index 0fa9229..b0580fd 100644
--- a/tensorflow/lite/examples/label_image/label_image.cc
+++ b/tensorflow/lite/examples/label_image/label_image.cc
@@ -55,47 +55,6 @@ double get_us(struct timeval t) { return (t.tv_sec * 1000000 + t.tv_usec); }
 using TfLiteDelegatePtr = tflite::Interpreter::TfLiteDelegatePtr;
 using TfLiteDelegatePtrMap = std::map<std::string, TfLiteDelegatePtr>;
 
-TfLiteDelegatePtr CreateGPUDelegate(Settings* s) {
-#if defined(__ANDROID__)
-  TfLiteGpuDelegateOptions options;
-  options.metadata = TfLiteGpuDelegateGetModelMetadata(s->model->GetModel());
-  if (s->allow_fp16) {
-    options.compile_options.precision_loss_allowed = 1;
-  } else {
-    options.compile_options.precision_loss_allowed = 0;
-  }
-  options.compile_options.preferred_gl_object_type =
-      TFLITE_GL_OBJECT_TYPE_FASTEST;
-  options.compile_options.dynamic_batch_enabled = 0;
-
-  return evaluation::CreateGPUDelegate(s->model, &options);
-#else
-  return evaluation::CreateGPUDelegate(s->model);
-#endif
-}
-
-TfLiteDelegatePtrMap GetDelegates(Settings* s) {
-  TfLiteDelegatePtrMap delegates;
-  if (s->gl_backend) {
-    auto delegate = CreateGPUDelegate(s);
-    if (!delegate) {
-      LOG(INFO) << "GPU acceleration is unsupported on this platform.";
-    } else {
-      delegates.emplace("GPU", std::move(delegate));
-    }
-  }
-
-  if (s->accel) {
-    auto delegate = evaluation::CreateNNAPIDelegate();
-    if (!delegate) {
-      LOG(INFO) << "NNAPI acceleration is unsupported on this platform.";
-    } else {
-      delegates.emplace("NNAPI", evaluation::CreateNNAPIDelegate());
-    }
-  }
-  return delegates;
-}
-
 // Takes a file name, and loads a list of labels from it, one per line, and
 // returns a vector of the strings. It pads with empty strings so the length
 // of the result is a multiple of 16, because our model expects that.
@@ -162,7 +121,6 @@ void RunInference(Settings* s) {
     exit(-1);
   }
 
-  interpreter->UseNNAPI(s->old_accel);
   interpreter->SetAllowFp16PrecisionForFp32(s->allow_fp16);
 
   if (s->verbose) {
@@ -203,16 +161,6 @@ void RunInference(Settings* s) {
     LOG(INFO) << "number of outputs: " << outputs.size() << "\n";
   }
 
-  auto delegates_ = GetDelegates(s);
-  for (const auto& delegate : delegates_) {
-    if (interpreter->ModifyGraphWithDelegate(delegate.second.get()) !=
-        kTfLiteOk) {
-      LOG(FATAL) << "Failed to apply " << delegate.first << " delegate.";
-    } else {
-      LOG(INFO) << "Applied " << delegate.first << " delegate.";
-    }
-  }
-
   if (interpreter->AllocateTensors() != kTfLiteOk) {
     LOG(FATAL) << "Failed to allocate tensors!";
   }
-- 
2.7.4

